---
layout: post
title: How to render something behind everything else
description:
tag: Game Dev ðŸ‘¾
---

I'm working on a skybox in Unity, with a sun that moves to match the scene's main directional light. The style is blocky and inspired by Minecraft, so the sun needs to be square.

Note this post was written while working with version 2022.3.15f1 of the Unity editor, and using the universal render pipeline.

## Option 1: Procedural skybox shader

My first approach was to do it the same way as the procedural skybox - in the shader - so I created a new shader graph. I managed to make it work as the shader for the skybox material after disabling "cast shadows" and setting depth write to "force disabled".

The basic idea behind a skybox shader is to use the normalized world position as the view direction, and using that to determine what each pixel in the far away sky should display.

I quickly realized however that even something as simple as drawing a square sun could be quite complex, requiring things like:

1. With the main light's direction as the sun's Z axis, using cross product to determine its X and Y axes (using global Y as the up axis).
1. Projecting view direction onto the sun's plane
1. Displaying a "sun" pixel where projection is smaller than some threshold when decomposed into sun's X and Y axes
1. Avoiding a second sun opposite to the main light by ignoring the case where view direction is looking away from main light

![Blend tree]({% link assets/2023-12-14-z-buffer/skybox-shader-graph.jpeg %})

![Blend tree]({% link assets/2023-12-14-z-buffer/skybox-square-sun.jpeg %})

## Option 2: Camera stacking

Another option is to have a second camera that renders only skybox elements. I did not want to try this route as a second camera seems to make the scene too complex and harder to manipulate and understand, not to mention for the likely higher impact on performance.

## Option 3: Skybox objects in main camera

A reasonably elegant option seems to be having skybox elements - such as the sun - inside the scene, as regular objects and alongside all others (although placed somewhat far from the camera). They would also be rendered by the main camera, with no need for a multi camera setup.

### Simply placing objects far away

To make these objects render behind everything else, one could simply physically place them behind everything else - only slightly less distant than the camera's frustum's far plane.

This feels a little fragile however - I wouldn't be totally sure that some edge case would cause elements to momentarily snap behind the camera's far plane, causing hard to detect bugs.

I also don't want to be limited as to how far I can place other objects. If I want to have a world so large or a camera frustum so small that the two meet, the skybox should remain unaffected.

I concluded I had to set up a material & shader combination such that an object will render behind everything else except the skybox, regardless of how far away it is from the camera.

This required reading up on the z-buffer, depth writing/checking, and render queues.

### Depth priming

I also spent a few too many hours wondering why things weren't working until I tried **disabling depth priming in the URP renderer settings**. It seems there is [some bug](https://forum.unity.com/threads/depth-priming-breaks-depth-write.1527241/) (or maybe just obscure behavior) with this feature.

### Skybox renders over objects that don't write to z-buffer

By disabling z-buffer/depth writing and rendering skybox objects first (smaller render queue value), one can render an object behind everything else. The problem is that once one adds a skybox material, it will start drawing over our objects as well - because the z-buffer doesn't know about them.

And we can't make the objects draw after the skybox (higher render queue value) because then they will also render over other objects (which objects depending on the depth test value).

### URP "Render Objects" renderer feature

One can also go about these things with a renderer feature in URP called "[Render Objects](https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@14.0/manual/renderer-features/renderer-feature-render-objects.html)", which requires using a layer to treat some objects differently. It allows one to set z-buffer options, and to override the render queue in the form of choosing from a list of "events" (such as "after drawing skybox").

However, setting up a skybox through a layer is harder to notice for people trying to make sense of the scene in the Unity editor. It does not set up expectations correctly by easily going unnoticed. In comparison, a material and/or shader with a descriptive name is a much more semantic way of saying "this object is treated in a special way".

### Option 3 summary

In conclusion, we can have skybox objects in the main camera as long as we don't set a skybox material in the lighting settings. We can do this by disabling depth writing and setting a lower value for the render queue in the material inspector (not possible for all materials, but creating a shader graph with the "allow material override" box checked should expose these).

This however means that we're always drawing skybox objects even if they're not on screen, which is not ideal, and is the reason the skybox only gets drawn later in the queue.

What we could really use is a way to only draw a pixel (meaning run a fragment shader) if its depth is still unset in the z-buffer, and draw skybox objects after the skybox itself (assuming the skybox does not write to the z-buffer).

This is equivalent to defining a custom depth check, which is not currently possible in the Unity engine (maybe with a custom scriptable render pipeline).
